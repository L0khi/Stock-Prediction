ğŸ“ˆ Logistic Regression â€“ Bank Marketing Dataset
This project applies Logistic Regression on a real-world bank marketing dataset.
It demonstrates the full preprocessing pipeline and a clean implementation of training preparation steps.

âœï¸ Author Note
I created this project a few months ago while learning foundational ML, including Logistic Regression, SMOTE balancing, and one-hot encodingâ€”all manually coded instead of relying on high-level wrappers.

Inspired by lessons from Andrej Karpathy and Andrew Ng.

ğŸ§  Project Highlights
ğŸ“Š Dataset: Bank Marketing Data (CSV)
ğŸ·ï¸ Target: Whether a client subscribed to a term deposit (y)
ğŸ”¢ Preprocessing:
Manual one-hot encoding (with NumPy + mapping)
SMOTE balancing for imbalanced binary classes
Standard normalization
ğŸ§ª Data split: 4000 samples for training, rest for testing
ğŸ“ File Structure
.
â”œâ”€â”€ LogisticRegression_Cleaned_For_GitHub.ipynb
â”œâ”€â”€ data/
â”‚   â””â”€â”€ bank_refined.csv  # <- Place your dataset here
ğŸ“¦ Requirements
pip install numpy pandas matplotlib imbalanced-learn
ğŸ’¡ Sample Code Snippet
from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)
ğŸš€ Future Enhancements
Add model training + evaluation cells
Accuracy/Confusion Matrix plotting
ROC Curve visualization
ğŸ“š Reference
Andrej Karpathy's Micrograd
Andrew Ngâ€™s ML Specialization
